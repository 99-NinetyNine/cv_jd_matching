"""
Enhanced admin endpoints with comprehensive evaluation and performance metrics.
"""

from fastapi import APIRouter, Depends, HTTPException
from sqlmodel import Session, select, func
from core.db.engine import get_session
from core.db.models import User, CV, Job, UserInteraction, Prediction, Application
from core.auth.security import verify_password
from api.routers.auth import get_current_user
from api.schemas.responses import (
    SystemHealthResponse,
    BatchTriggerResponse
)
from typing import List, Dict, Optional, Any
from datetime import datetime, timedelta
import logging
import os

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/admin", tags=["admin"])


@router.get("/evaluation_metrics")
async def get_evaluation_metrics(
    session: Session = Depends(get_session),
    days: int = 30
) -> Dict[str, Any]:
    """
    Get comprehensive evaluation metrics for the recommendation system.
    Includes CTR, conversion rates, intrinsic/extrinsic factors.

    Args:
        days: Number of days to analyze (default 30)
    """
    cutoff_date = datetime.utcnow() - timedelta(days=days)

    # Get all interactions in time period
    interactions = session.exec(
        select(UserInteraction).where(UserInteraction.timestamp >= cutoff_date)
    ).all()

    # Calculate engagement metrics
    saved_count = len([i for i in interactions if i.action == "saved"])
    applied_count = len([i for i in interactions if i.action == "applied"])

    # Get all applications
    applications = session.exec(
        select(Application).where(Application.applied_at >= cutoff_date)
    ).all()

    # Save-to-Apply Conversion: Of saved jobs, how many were applied to?
    # Find jobs that were both saved AND applied
    saved_job_ids = set(i.job_id for i in interactions if i.action == "saved")
    applied_job_ids = set(i.job_id for i in interactions if i.action == "applied")
    saved_then_applied = saved_job_ids.intersection(applied_job_ids)

    save_to_apply_rate = (len(saved_then_applied) / len(saved_job_ids) * 100) if saved_job_ids else 0

    # Direct Apply Rate: Applications without saving first
    direct_applies = applied_job_ids - saved_job_ids
    direct_apply_rate = (len(direct_applies) / len(applied_job_ids) * 100) if applied_job_ids else 0

    # Conversion funnel
    saved_jobs = len(set(i.job_id for i in interactions if i.action == "saved"))
    applied_jobs = len(set(i.job_id for i in interactions if i.action == "applied"))
    hired_count = len([i for i in interactions if i.action == "hired"])

    # Calculate acceptance rate (hirer perspective)
    accepted_apps = len([a for a in applications if a.status == "accepted"])
    acceptance_rate = (accepted_apps / len(applications) * 100) if applications else 0

    # Intrinsic factors (from system design)
    intrinsic_factors = {
        "skills_match_weight": 0.35,
        "experience_match_weight": 0.25,
        "education_match_weight": 0.15,
        "semantic_similarity_weight": 0.25,
        "reranker_enabled": True,
        "nlp_skills_extraction": True,
        "semantic_skills_matching": True
    }

    # Extrinsic factors (user behavior)
    applied_interactions = [i for i in interactions if i.action == "applied" and i.interaction_metadata]
    hired_interactions = [i for i in interactions if i.action == "hired" and i.interaction_metadata]

    # Extract match scores if available in metadata
    avg_match_score_applied = 0.0
    avg_match_score_hired = 0.0

    if applied_interactions:
        scores = [
            i.interaction_metadata.get("match_score", 0)
            for i in applied_interactions
            if i.interaction_metadata and "match_score" in i.interaction_metadata
        ]
        avg_match_score_applied = sum(scores) / len(scores) if scores else 0.0

    if hired_interactions:
        scores = [
            i.interaction_metadata.get("match_score", 0)
            for i in hired_interactions
            if i.interaction_metadata and "match_score" in i.interaction_metadata
        ]
        avg_match_score_hired = sum(scores) / len(scores) if scores else 0.0

    # Time-based metrics
    peak_hour = _get_peak_hour(interactions)

    # User engagement score (applied / saved ratio)
    user_engagement_score = (applied_count / saved_count) if saved_count > 0 else 0

    # Top performing jobs
    job_interactions = {}
    for interaction in interactions:
        job_id = interaction.job_id
        if job_id not in job_interactions:
            job_interactions[job_id] = {"saved": 0, "applied": 0, "hired": 0}
        action = interaction.action
        if action in job_interactions[job_id]:
            job_interactions[job_id][action] += 1

    top_jobs = sorted(
        job_interactions.items(),
        key=lambda x: x[1].get("applied", 0),
        reverse=True
    )[:10]

    # Calculate precision and recall (simplified)
    # Relevant = applied or hired
    relevant_count = len([i for i in interactions if i.action in ["applied", "hired"]])
    total_recommended = saved_count

    precision = (relevant_count / total_recommended) if total_recommended > 0 else 0
    # Recall is harder to calculate without ground truth, use approximation
    recall = (relevant_count / (relevant_count + 10)) if relevant_count > 0 else 0  # Approximation
    f1_score = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0

    return {
        "period_days": days,
        "generated_at": datetime.utcnow().isoformat(),
        "summary": {
            "total_interactions": len(interactions),
            "total_saved": saved_count,
            "total_applications": applied_count,
            "total_hired": hired_count,
            "save_to_apply_percent": round(save_to_apply_rate, 2),
            "direct_apply_percent": round(direct_apply_rate, 2),
            "acceptance_rate_percent": round(acceptance_rate, 2)
        },
        "quality_metrics": {
            "precision": round(precision, 3),
            "recall": round(recall, 3),
            "f1_score": round(f1_score, 3)
        },
        "conversion_funnel": {
            "saved": saved_jobs,
            "applied": applied_jobs,
            "hired": hired_count,
            "saved_to_apply_percent": round((applied_jobs / saved_jobs * 100), 2) if saved_jobs > 0 else 0,
            "apply_to_hire_percent": round((hired_count / applied_jobs * 100), 2) if applied_jobs > 0 else 0
        },
        "intrinsic_factors": intrinsic_factors,
        "extrinsic_factors": {
            "avg_match_score_applied": round(avg_match_score_applied, 3),
            "avg_match_score_hired": round(avg_match_score_hired, 3),
            "peak_interaction_hour": peak_hour,
            "user_engagement_score": round(user_engagement_score, 3)
        },
        "top_jobs": [
            {
                "job_id": job_id,
                "saves": stats["saved"],
                "applications": stats["applied"],
                "hired": stats.get("hired", 0),
                "engagement_rate": round((stats["applied"] / stats["saved"] * 100), 2) if stats["saved"] > 0 else 0
            }
            for job_id, stats in top_jobs
        ],
        "actions_breakdown": {
            action: len([i for i in interactions if i.action == action])
            for action in ["saved", "applied", "shortlisted", "interviewed", "hired", "rejected"]
        }
    }


def _get_peak_hour(interactions: List[UserInteraction]) -> int:
    """Get the hour of day with most interactions."""
    if not interactions:
        return 0

    hour_counts = {}
    for interaction in interactions:
        hour = interaction.timestamp.hour
        hour_counts[hour] = hour_counts.get(hour, 0) + 1

    return max(hour_counts.items(), key=lambda x: x[1])[0] if hour_counts else 0


@router.get("/performance_dashboard")
async def get_performance_dashboard(
    session: Session = Depends(get_session)
) -> Dict[str, Any]:
    """
    Get comprehensive performance metrics for the admin dashboard.
    Includes parsing, embedding, matching, database performance, and recommendation generation time.

    This endpoint addresses Task 5 requirements:
    - Recommendation quality metrics (Precision, Recall, F1)
    - Performance metrics (generation time, throughput, DB latency)
    - Scalability assessment with large datasets
    """
    import time
    cutoff_24h = datetime.utcnow() - timedelta(hours=24)

    # === DATABASE LATENCY MEASUREMENTS ===
    db_latency = {}

    # Test 1: Simple count query
    start = time.perf_counter()
    total_cvs = session.exec(select(func.count(CV.id))).one()
    db_latency["simple_count_ms"] = round((time.perf_counter() - start) * 1000, 2)

    # Test 2: Complex join query (CV + predictions)
    start = time.perf_counter()
    recent_predictions = session.exec(
        select(Prediction).where(Prediction.created_at >= cutoff_24h).limit(100)
    ).all()
    db_latency["prediction_query_ms"] = round((time.perf_counter() - start) * 1000, 2)

    # Test 3: Embedding similarity search simulation (vector distance)
    start = time.perf_counter()
    cvs_with_embeddings = session.exec(
        select(CV).where(CV.embedding_status == "completed").limit(10)
    ).all()
    db_latency["vector_fetch_ms"] = round((time.perf_counter() - start) * 1000, 2)

    # === BATCH REQUEST FETCHING (OpenAI Batches) ===
    from core.db.models import BatchRequest
    from collections import defaultdict

    recent_batches = session.exec(
        select(BatchRequest).where(BatchRequest.created_at >= cutoff_24h)
    ).all()

    # === RECOMMENDATION GENERATION TIME ===
    # Fetch recent predictions with timestamps
    recent_predictions = session.exec(
        select(Prediction)
        .where(Prediction.created_at >= cutoff_24h)
        .where(Prediction.explanation_completed_at.isnot(None))  # Only predictions with complete explanations
    ).all()

    if recent_predictions:
        first_time_gen_times = []
        recurring_gen_times = []

        for pred in recent_predictions:
            # Get the CV to check created_at timestamp
            try:
                cv_id = int(pred.cv_id)
            except (ValueError, TypeError):
                # Skip predictions with invalid cv_id (UUIDs from old data)
                logger.warning(f"Skipping prediction {pred.prediction_id} with invalid cv_id: {pred.cv_id}")
                continue

            cv = session.get(CV, cv_id)
            if not cv or not pred.explanation_completed_at:
                continue

            if pred.is_first_prediction:
                # First-time CV: Total time from CV upload to explanation completion
                total_time_ms = (pred.explanation_completed_at - cv.created_at).total_seconds() * 1000
                first_time_gen_times.append(total_time_ms)
            else:
                # Recurring CV: Time from matching to explanation completion
                if pred.matching_completed_at:
                    gen_time_ms = (pred.explanation_completed_at - pred.matching_completed_at).total_seconds() * 1000
                    recurring_gen_times.append(gen_time_ms)

        # Calculate statistics
        all_times = first_time_gen_times + recurring_gen_times

        if all_times:
            sorted_times = sorted(all_times)
            rec_gen_stats = {
                "avg_ms": round(sum(all_times) / len(all_times), 2),
                "min_ms": round(min(all_times), 2),
                "max_ms": round(max(all_times), 2),
                "p50_ms": round(sorted_times[len(sorted_times)//2], 2),
                "p95_ms": round(sorted_times[int(len(sorted_times)*0.95)], 2) if len(sorted_times) > 1 else round(max(all_times), 2),
                "p99_ms": round(sorted_times[int(len(sorted_times)*0.99)], 2) if len(sorted_times) > 20 else round(max(all_times), 2),
                "sample_count": len(all_times),
                "first_time_cv_count": len(first_time_gen_times),
                "recurring_cv_count": len(recurring_gen_times),
                "first_time_avg_ms": round(sum(first_time_gen_times) / len(first_time_gen_times), 2) if first_time_gen_times else 0,
                "recurring_avg_ms": round(sum(recurring_gen_times) / len(recurring_gen_times), 2) if recurring_gen_times else 0,
                "data_source": "Prediction timestamps"
            }
        else:
            rec_gen_stats = {"note": "No completed predictions with timestamps in last 24h"}
    else:
        rec_gen_stats = {
            "note": "No predictions with explanation timestamps found. Upload CVs and trigger matching to generate metrics."
        }

    # === SYSTEM THROUGHPUT ===
    recent_predictions_count = session.exec(
        select(func.count(Prediction.id)).where(Prediction.created_at >= cutoff_24h)
    ).one()

    recent_cvs_count = session.exec(
        select(func.count(CV.id)).where(CV.created_at >= cutoff_24h)
    ).one()

    recent_interactions_count = session.exec(
        select(func.count(UserInteraction.id)).where(UserInteraction.timestamp >= cutoff_24h)
    ).one()

    throughput = {
        "recommendations_per_hour": round(recent_predictions_count / 24, 2),
        "recommendations_last_24h": recent_predictions_count,
        "cv_uploads_per_hour": round(recent_cvs_count / 24, 2),
        "interactions_per_hour": round(recent_interactions_count / 24, 2)
    }

    # === PARSING & EMBEDDING PERFORMANCE ===
    recent_cvs = session.exec(
        select(CV).where(CV.created_at >= cutoff_24h)
    ).all()

    # Single-pass aggregation for parsing and embedding stats
    parsing_completed = parsing_failed = parsing_pending = 0
    embedding_completed = embedding_failed = embedding_pending = 0

    for cv in recent_cvs:
        # Parsing stats
        if cv.parsing_status == "completed":
            parsing_completed += 1
        elif cv.parsing_status == "failed":
            parsing_failed += 1
        elif cv.parsing_status in ["pending", "pending_batch", "processing"]:
            parsing_pending += 1

        # Embedding stats
        if cv.embedding_status == "completed":
            embedding_completed += 1
        elif cv.embedding_status == "failed":
            embedding_failed += 1
        elif cv.embedding_status in ["pending", "pending_batch", "processing"]:
            embedding_pending += 1

    # === BATCH STATUS SUMMARY ===
    # Single-pass aggregation
    batch_summary = {
        "total": len(recent_batches),
        "validating": 0,
        "in_progress": 0,
        "completed": 0,
        "failed": 0,
        "expired": 0,
        "cancelled": 0,
        "processing": 0,  # Add for frontend compatibility
        "pending": 0  # Add for frontend compatibility
    }

    for batch in recent_batches:
        status = batch.status
        if status in batch_summary:
            batch_summary[status] += 1

    # === BATCH PERFORMANCE METRICS ===
    completed_batches = [b for b in recent_batches if b.status == "completed" and b.completed_at]

    batch_type_metrics = defaultdict(lambda: {
        "count": 0,
        "total_items": 0,
        "total_runtime_sec": 0,
        "runtimes": []
    })

    for batch in completed_batches:
        batch_type = batch.batch_metadata.get("type", "unknown")
        sub_type = batch.batch_metadata.get("sub_type", "")
        type_key = f"{batch_type}_{sub_type}" if sub_type else batch_type

        runtime_sec = (batch.completed_at - batch.created_at).total_seconds()
        item_count = int(batch.batch_metadata.get("count", 0))

        batch_type_metrics[type_key]["count"] += 1
        batch_type_metrics[type_key]["total_items"] += item_count
        batch_type_metrics[type_key]["total_runtime_sec"] += runtime_sec
        batch_type_metrics[type_key]["runtimes"].append(runtime_sec)

    # Calculate averages and throughput per batch type
    batch_performance_breakdown = {}
    for type_key, metrics in batch_type_metrics.items():
        if metrics["count"] > 0:
            avg_runtime = metrics["total_runtime_sec"] / metrics["count"]
            avg_items = metrics["total_items"] / metrics["count"]
            throughput_batch = metrics["total_items"] / metrics["total_runtime_sec"] if metrics["total_runtime_sec"] > 0 else 0

            batch_performance_breakdown[type_key] = {
                "batch_count": metrics["count"],
                "total_items_processed": metrics["total_items"],
                "avg_runtime_sec": round(avg_runtime, 2),
                "avg_items_per_batch": round(avg_items, 1),
                "avg_throughput_items_per_sec": round(throughput_batch, 2),
                "min_runtime_sec": round(min(metrics["runtimes"]), 2) if metrics["runtimes"] else 0,
                "max_runtime_sec": round(max(metrics["runtimes"]), 2) if metrics["runtimes"] else 0
            }

    # Overall batch performance
    if completed_batches:
        total_items_processed = sum(int(b.batch_metadata.get("count", 0)) for b in completed_batches)
        total_runtime = sum((b.completed_at - b.created_at).total_seconds() for b in completed_batches)
        avg_batch_runtime = total_runtime / len(completed_batches)

        batch_performance = {
            "total_batches_completed_24h": len(completed_batches),
            "total_items_processed_24h": total_items_processed,
            "avg_batch_runtime_sec": round(avg_batch_runtime, 2),
            "overall_throughput_items_per_sec": round(total_items_processed / total_runtime, 2) if total_runtime > 0 else 0,
            "by_type": batch_performance_breakdown
        }
    else:
        batch_performance = {
            "total_batches_completed_24h": 0,
            "note": "No completed batches in the last 24 hours"
        }

    # === DATABASE SIZES & SCALABILITY ===
    total_jobs = session.exec(select(func.count(Job.id))).one()
    cvs_with_embeddings = session.exec(
        select(func.count(CV.id)).where(CV.embedding_status == "completed")
    ).one()
    jobs_with_embeddings = session.exec(
        select(func.count(Job.id)).where(Job.embedding_status == "completed")
    ).one()

    # Scalability assessment
    scalability = {
        "dataset_size": {
            "total_cvs": total_cvs,
            "total_jobs": total_jobs,
            "cvs_with_embeddings": cvs_with_embeddings,
            "jobs_with_embeddings": jobs_with_embeddings,
            "embedding_coverage_percent": round((cvs_with_embeddings / total_cvs * 100), 2) if total_cvs > 0 else 0
        },
        "vector_search_ready": cvs_with_embeddings > 0 and jobs_with_embeddings > 0,
        "estimated_capacity": {
            "note": "Based on current performance metrics",
            "max_concurrent_recommendations": round(1000 / rec_gen_stats.get("avg_ms", 100) * 60) if rec_gen_stats.get("avg_ms", 0) > 0 else "N/A",
            "db_query_efficiency": "Good" if db_latency["simple_count_ms"] < 50 else "Needs optimization"
        }
    }

    # === RECOMMENDATION QUALITY METRICS ===
    interactions_24h = session.exec(
        select(UserInteraction).where(UserInteraction.timestamp >= cutoff_24h)
    ).all()

    # Single-pass aggregation for interaction counts
    viewed_count = applied_count = hired_count = 0
    for interaction in interactions_24h:
        if interaction.action == "saved":
            viewed_count += 1
        elif interaction.action == "applied":
            applied_count += 1
        elif interaction.action == "hired":
            hired_count += 1

    # Calculate quality metrics
    precision = (applied_count / viewed_count) if viewed_count > 0 else 0
    recall = (applied_count / (applied_count + 5)) if applied_count > 0 else 0  # Approximation
    f1_score = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0

    quality_metrics = {
        "precision": round(precision, 3),
        "recall": round(recall, 3),
        "f1_score": round(f1_score, 3),
        "ctr_percent": round((applied_count / viewed_count * 100), 2) if viewed_count > 0 else 0,
        "hire_rate_percent": round((hired_count / applied_count * 100), 2) if applied_count > 0 else 0
    }

    total_recent_cvs = len(recent_cvs)

    return {
        "period": "Last 24 hours",
        "timestamp": datetime.utcnow().isoformat(),

        # === TASK 5: PERFORMANCE METRICS ===
        "recommendation_performance": {
            "generation_time": rec_gen_stats,
            "throughput": throughput,
            "quality_metrics": quality_metrics
        },

        "database_performance": {
            "latency": db_latency,
            "query_efficiency": "Excellent" if db_latency["simple_count_ms"] < 10 else "Good" if db_latency["simple_count_ms"] < 50 else "Needs optimization"
        },

        "scalability_assessment": scalability,

        # === EXISTING METRICS ===
        "parsing": {
            "total_processed": total_recent_cvs,
            "completed": parsing_completed,
            "failed": parsing_failed,
            "pending": parsing_pending,
            "success_rate_percent": round((parsing_completed / total_recent_cvs * 100), 2) if total_recent_cvs else 0
        },
        "embedding": {
            "total_processed": total_recent_cvs,
            "completed": embedding_completed,
            "failed": embedding_failed,
            "pending": embedding_pending,
            "success_rate_percent": round((embedding_completed / total_recent_cvs * 100), 2) if total_recent_cvs else 0
        },
        # Frontend compatibility: batch_jobs expects these exact fields
        "batch_jobs": {
            "total": batch_summary["total"],
            "pending": batch_summary["pending"],
            "processing": batch_summary["processing"] + batch_summary["in_progress"],  # Combine processing states
            "completed": batch_summary["completed"],
            "failed": batch_summary["failed"]
        },
        "batch_status": batch_summary,
        "batch_performance": batch_performance
    }


@router.post("/test_celery")
async def test_celery_worker() -> Dict[str, Any]:
    """Test if Celery worker is running."""
    try:
        from core.worker.tasks import test_celery_task
        result = test_celery_task.delay("Admin test message")
        return {
            "status": "success",
            "message": "Celery task queued successfully",
            "task_id": result.id,
            "note": "Check Celery worker logs to verify execution"
        }
    except Exception as e:
        logger.error(f"Celery test failed: {e}")
        return {
            "status": "error",
            "message": str(e),
            "note": "Celery worker may not be running. Start with: celery -A core.worker.celery_app worker --loglevel=info"
        }


@router.post("/trigger_batch_parsing")
async def trigger_batch_parsing() -> Dict[str, Any]:
    """Trigger batch CV parsing task."""
    try:
        from core.worker.tasks import process_batch_cv_parsing
        result = process_batch_cv_parsing.delay()
        return {
            "status": "success",
            "message": "Batch parsing task queued",
            "task_id": result.id,
            "note": "CVs with parsing_status='pending_batch' will be processed"
        }
    except Exception as e:
        logger.error(f"Batch parsing trigger failed: {e}")
        return {
            "status": "error",
            "message": str(e)
        }


@router.get("/system_health", response_model=SystemHealthResponse)
async def get_system_health(
    session: Session = Depends(get_session)
) -> SystemHealthResponse:
    """
    Get overall system health status.

    Returns comprehensive health information about system components including
    database connectivity, Celery workers, pending work items, and recent failures.

    **Returns:** Health status for all system components
    """
    try:
        # Database connectivity
        db_check = session.exec(select(func.count(CV.id))).one() is not None

        # Count pending items
        pending_parsing = session.exec(
            select(func.count(CV.id)).where(CV.parsing_status.in_(["pending", "pending_batch"]))
        ).one()

        pending_embedding = session.exec(
            select(func.count(CV.id)).where(CV.embedding_status.in_(["pending", "pending_batch"]))
        ).one()

        # Check for recent failures
        recent_failures = session.exec(
            select(func.count(CV.id)).where(
                CV.parsing_status == "failed",
                CV.created_at >= datetime.utcnow() - timedelta(hours=1)
            )
        ).one()

        # Celery health (attempt to check)
        celery_healthy = True
        try:
            from core.worker.celery_app import celery_app
            # Check if we can get celery stats
            inspect = celery_app.control.inspect()
            active_workers = inspect.active()
            celery_healthy = active_workers is not None and len(active_workers) > 0
        except Exception:
            celery_healthy = False

        overall_status = "healthy" if (db_check and celery_healthy and recent_failures < 10) else "degraded"

        return {
            "status": overall_status,
            "timestamp": datetime.utcnow().isoformat(),
            "components": {
                "database": "healthy" if db_check else "unhealthy",
                "celery_workers": "healthy" if celery_healthy else "unhealthy",
                "api": "healthy"
            },
            "pending_work": {
                "parsing": pending_parsing,
                "embedding": pending_embedding
            },
            "recent_failures": recent_failures
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {
            "status": "error",
            "message": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }


@router.get("/batches")
async def list_batch_requests(
    session: Session = Depends(get_session),
    limit: int = 50,
    status_filter: Optional[str] = None
) -> Dict[str, Any]:
    """
    List OpenAI Batch API requests with optional filtering.

    Retrieve batch requests for monitoring and tracking. Results are ordered by
    creation date (newest first) and can be filtered by status.

    **Query Parameters:**
    - limit: Maximum results (default: 50, max: 200)
    - status_filter: Filter by status (validating, in_progress, completed, failed, etc.)

    **Returns:** List of batch requests with details

    **Example:**
    ```
    GET /admin/batches?status_filter=in_progress&limit=20
    ```
    """
    try:
        from core.db.models import BatchRequest

        limit = min(limit, 200)  # Cap at 200

        query = select(BatchRequest).order_by(BatchRequest.created_at.desc()).limit(limit)

        if status_filter:
            query = query.where(BatchRequest.status == status_filter)

        batches = session.exec(query).all()

        # Convert to dict for response
        batch_list = []
        for batch in batches:
            batch_list.append({
                "id": batch.id,
                "batch_api_id": batch.batch_api_id,
                "status": batch.status,
                "batch_type": batch.batch_metadata.get("type", "unknown"),
                "request_counts": batch.request_counts,
                "created_at": batch.created_at.isoformat(),
                "completed_at": batch.completed_at.isoformat() if batch.completed_at else None
            })

        return {
            "batches": batch_list,
            "count": len(batch_list)
        }
    except Exception as e:
        logger.error(f"Failed to list batches: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/batches/trigger", response_model=BatchTriggerResponse)
async def trigger_batch_processing(
    batch_type: str = "embedding",
    session: Session = Depends(get_session)
) -> BatchTriggerResponse:
    """
    Trigger batch processing for CVs or jobs.

    Initiates batch processing tasks for pending items. Supports different
    batch types including embedding generation, CV parsing, and matching.

    **Query Parameters:**
    - batch_type: Type of batch - "embedding", "parsing", or "matching" (default: "embedding")

    **Returns:** Status and task identifier

    **Raises:**
    - 400: Invalid batch_type
    - 500: Batch trigger failed

    **Example:**
    ```
    POST /admin/batches/trigger?batch_type=embedding
    ```
    """
    try:
        if batch_type == "embedding":
            # Count pending items
            pending_cvs = session.exec(
                select(func.count(CV.id)).where(CV.embedding_status == "pending_batch")
            ).one()

            pending_jobs = session.exec(
                select(func.count(Job.id)).where(Job.embedding_status == "pending_batch")
            ).one()

            if pending_cvs == 0 and pending_jobs == 0:
                return BatchTriggerResponse(
                    status="success",
                    message="No items pending batch embedding",
                    batch_id=None
                )

            try:
                from core.worker.tasks import submit_cv_batch_embeddings_task, submit_batch_job_embeddings_task

                tasks_queued = []
                if pending_cvs > 0:
                    result = submit_cv_batch_embeddings_task.delay()
                    tasks_queued.append(f"CV embeddings (task: {result.id})")

                if pending_jobs > 0:
                    result = submit_batch_job_embeddings_task.delay()
                    tasks_queued.append(f"Job embeddings (task: {result.id})")

                return BatchTriggerResponse(
                    status="success",
                    message=f"Queued: {', '.join(tasks_queued)}. Total: {pending_cvs} CVs, {pending_jobs} jobs",
                    batch_id=None,
                    task_id=result.id if tasks_queued else None
                )
            except Exception as e:
                logger.error(f"Celery task failed: {e}")
                return BatchTriggerResponse(
                    status="error",
                    message=f"Celery not available: {str(e)}",
                    batch_id=None,
                    task_id=None
                )

        elif batch_type == "parsing":
            pending_cvs = session.exec(
                select(func.count(CV.id)).where(CV.parsing_status == "pending_batch")
            ).one()

            if pending_cvs == 0:
                return BatchTriggerResponse(
                    status="success",
                    message="No CVs pending batch parsing",
                    batch_id=None
                )

            try:
                from core.worker.tasks import process_batch_cv_parsing
                result = process_batch_cv_parsing.delay()
                return BatchTriggerResponse(
                    status="success",
                    message=f"Batch parsing task queued for {pending_cvs} CVs",
                    batch_id=None,
                    task_id=result.id
                )
            except Exception as e:
                logger.error(f"Celery task failed: {e}")
                return BatchTriggerResponse(
                    status="error",
                    message=f"Celery not available: {str(e)}",
                    batch_id=None,
                    task_id=None
                )

        elif batch_type == "matching":
            try:
                from core.worker.tasks import perform_batch_matches
                result = perform_batch_matches.delay()
                return BatchTriggerResponse(
                    status="success",
                    message="Batch matching task queued",
                    batch_id=None,
                    task_id=result.id
                )
            except Exception as e:
                logger.error(f"Celery task failed: {e}")
                return BatchTriggerResponse(
                    status="error",
                    message=f"Celery not available: {str(e)}",
                    batch_id=None,
                    task_id=None
                )

        else:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid batch_type: {batch_type}. Must be 'embedding', 'parsing', or 'matching'"
            )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Batch trigger failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/batches/check")
async def check_batch_status() -> Dict[str, Any]:
    """
    Check and update status of all active batch jobs.

    Triggers the Celery task that polls OpenAI Batch API for status updates
    on in-progress batches and processes completed results.

    **Returns:** Task status

    **Example:**
    ```
    POST /admin/batches/check
    ```
    """
    try:
        from core.worker.tasks import check_batch_status_task
        result = check_batch_status_task.delay()
        return {
            "status": "success",
            "message": "Batch status check task queued",
            "task_id": result.id
        }
    except Exception as e:
        logger.error(f"Failed to queue batch status check: {e}")
        return {
            "status": "error",
            "message": f"Celery not available: {str(e)}"
        }


@router.get("/cache_metrics")
async def get_cache_metrics() -> Dict[str, Any]:
    """
    Get Redis cache performance metrics.

    Provides comprehensive cache statistics including:
    - Hit/Miss rates
    - Memory usage
    - Key distribution by pattern
    - Eviction statistics
    - Cache efficiency metrics

    **Returns:** Complete cache performance dashboard data
    """
    try:
        from core.cache.redis_cache import redis_client as REDIS_CLIENT
        import time

        redis_client = REDIS_CLIENT.client

        # Get Redis info
        info = redis_client.info()
        stats = redis_client.info('stats')
        memory_stats = redis_client.info('memory')

        # Calculate hit rate
        keyspace_hits = int(stats.get('keyspace_hits', 0))
        keyspace_misses = int(stats.get('keyspace_misses', 0))
        total_requests = keyspace_hits + keyspace_misses
        hit_rate = (keyspace_hits / total_requests * 100) if total_requests > 0 else 0

        # Get key counts by pattern
        key_patterns = {
            'match_results': 'match_results:*',
            'cv_embeddings': 'cv_embedding:*',
            'job_embeddings': 'job_embedding:*',
            'cv_parsed': 'cv_parsed:*',
            'other': '*'
        }

        key_counts = {}
        for name, pattern in key_patterns.items():
            try:
                keys = redis_client.keys(pattern)
                key_counts[name] = len(keys)
            except Exception as e:
                logger.warning(f"Could not count keys for pattern {pattern}: {e}")
                key_counts[name] = 0

        # Test cache response time
        start = time.perf_counter()
        redis_client.ping()
        cache_latency_ms = round((time.perf_counter() - start) * 1000, 2)

        # Memory usage
        used_memory = memory_stats.get('used_memory', 0)
        used_memory_human = memory_stats.get('used_memory_human', '0B')
        max_memory = memory_stats.get('maxmemory', 0)
        memory_usage_percent = (used_memory / max_memory * 100) if max_memory > 0 else 0

        # Eviction stats
        evicted_keys = int(stats.get('evicted_keys', 0))
        expired_keys = int(stats.get('expired_keys', 0))

        # Connection stats
        connected_clients = int(info.get('connected_clients', 0))

        # Calculate cache efficiency score (0-100)
        efficiency_score = min(100, hit_rate * 0.7 + (100 - memory_usage_percent) * 0.3)

        return {
            "timestamp": datetime.utcnow().isoformat(),
            "status": "healthy" if hit_rate > 50 else "degraded" if hit_rate > 20 else "poor",

            "performance": {
                "hit_rate_percent": round(hit_rate, 2),
                "hits": keyspace_hits,
                "misses": keyspace_misses,
                "total_requests": total_requests,
                "cache_latency_ms": cache_latency_ms,
                "efficiency_score": round(efficiency_score, 2)
            },

            "memory": {
                "used_memory_human": used_memory_human,
                "used_memory_bytes": used_memory,
                "max_memory_bytes": max_memory,
                "memory_usage_percent": round(memory_usage_percent, 2),
                "fragmentation_ratio": float(memory_stats.get('mem_fragmentation_ratio', 1.0))
            },

            "keys": {
                "total_keys": redis_client.dbsize(),
                "by_pattern": key_counts,
                "evicted_keys": evicted_keys,
                "expired_keys": expired_keys
            },

            "connections": {
                "connected_clients": connected_clients,
                "blocked_clients": int(info.get('blocked_clients', 0)),
                "total_connections_received": int(stats.get('total_connections_received', 0))
            },

            "uptime": {
                "uptime_seconds": int(info.get('uptime_in_seconds', 0)),
                "uptime_days": round(int(info.get('uptime_in_seconds', 0)) / 86400, 2)
            },

            "recommendations": _generate_cache_recommendations(hit_rate, memory_usage_percent, evicted_keys)
        }

    except Exception as e:
        logger.error(f"Failed to fetch cache metrics: {e}")
        return {
            "status": "error",
            "message": f"Redis not available: {str(e)}",
            "timestamp": datetime.utcnow().isoformat()
        }


def _generate_cache_recommendations(hit_rate: float, memory_usage: float, evictions: int) -> List[str]:
    """Generate actionable recommendations based on cache metrics."""
    recommendations = []

    if hit_rate < 50:
        recommendations.append("âš ï¸ Low cache hit rate - Consider increasing TTL or caching more data")

    if memory_usage > 90:
        recommendations.append("ðŸ”´ High memory usage - Increase max memory or review cache eviction policy")
    elif memory_usage > 75:
        recommendations.append("âš ï¸ Memory usage approaching limit - Monitor closely")

    if evictions > 1000:
        recommendations.append("âš ï¸ High eviction count - Increase Redis memory allocation")

    if hit_rate > 80 and memory_usage < 70:
        recommendations.append("âœ… Cache performing optimally")

    if not recommendations:
        recommendations.append("âœ… No issues detected - cache is healthy")

    return recommendations
