{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Synthetic Data Maker from Kaggle Dataset\n",
                "\n",
                "This notebook processes the Kaggle Resume dataset, selects a few samples, and uses the LLM to convert them into the standard JSON Resume format.\n",
                "\n",
                "This is done because, we have to have a pdf => json paired dataset, kaggle had pdf => text format.\n",
                "\n",
                "Having text format simplifies most of the difficulties, but we are making a common pipeline, that way our evaluation pipeline works similarly for both cases.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/acer/Desktop/cv/venv/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.12) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
                        "  warnings.warn(message, FutureWarning)\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import sys\n",
                "import os\n",
                "import json\n",
                "from typing import List\n",
                "\n",
                "# Add parent directory to path to import core modules\n",
                "sys.path.append(os.path.abspath(\"../..\"))\n",
                "\n",
                "from core.llm.factory import get_llm\n",
                "from core.parsing.schema import Resume\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "from langchain_core.output_parsers import PydanticOutputParser"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset Shape: (2484, 4)\n",
                        "Categories: ['HR' 'DESIGNER' 'INFORMATION-TECHNOLOGY' 'TEACHER' 'ADVOCATE'\n",
                        " 'BUSINESS-DEVELOPMENT' 'HEALTHCARE' 'FITNESS' 'AGRICULTURE' 'BPO' 'SALES'\n",
                        " 'CONSULTANT' 'DIGITAL-MEDIA' 'AUTOMOBILE' 'CHEF' 'FINANCE' 'APPAREL'\n",
                        " 'ENGINEERING' 'ACCOUNTANT' 'CONSTRUCTION' 'PUBLIC-RELATIONS' 'BANKING'\n",
                        " 'ARTS' 'AVIATION']\n"
                    ]
                }
            ],
            "source": [
                "# Load Dataset\n",
                "csv_path = '/home/acer/Desktop/cv/core/parsing/tests_data/resume_and_texts_kaggle/all/Resume/Resume.csv'\n",
                "df = pd.read_csv(csv_path)\n",
                "\n",
                "print(\"Dataset Shape:\", df.shape)\n",
                "print(\"Categories:\", df['Category'].unique())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Selected 7 samples from categories: ['HR' 'DESIGNER' 'INFORMATION-TECHNOLOGY' 'TEACHER' 'ADVOCATE'\n",
                        " 'BUSINESS-DEVELOPMENT' 'HEALTHCARE']\n"
                    ]
                }
            ],
            "source": [
                "# Select 5 samples from different categories\n",
                "categories = df['Category'].unique()[:7]\n",
                "samples = []\n",
                "\n",
                "for cat in categories:\n",
                "    sample = df[df['Category'] == cat].iloc[0]\n",
                "    samples.append(sample)\n",
                "    \n",
                "print(f\"Selected {len(samples)} samples from categories: {categories}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize LLM and Parser\n",
                "llm = get_llm()\n",
                "parser = PydanticOutputParser(pydantic_object=Resume)\n",
                "\n",
                "def convert_to_json(text: str) -> Resume:\n",
                "    prompt = PromptTemplate(\n",
                "        template=\"\"\"Convert the following resume text into a valid JSON object matching the schema.\n",
                "        If information is missing, leave fields null or empty.\n",
                "        \n",
                "        RESUME TEXT:\n",
                "        {text}\n",
                "        \n",
                "        {format_instructions}\n",
                "        \"\"\",\n",
                "        input_variables=[\"text\"],\n",
                "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
                "    )\n",
                "    \n",
                "    chain = prompt | llm | parser\n",
                "    return chain.invoke({\"text\": text})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing 1/7: Category=HR, ID=16852973...\n",
                        "Saved to /home/acer/Desktop/cv/core/parsing/tests_data/resume_and_texts_kaggle/some/HR_16852973.json\n",
                        "Processing 2/7: Category=DESIGNER, ID=37058472...\n",
                        "Saved to /home/acer/Desktop/cv/core/parsing/tests_data/resume_and_texts_kaggle/some/DESIGNER_37058472.json\n",
                        "Processing 3/7: Category=INFORMATION-TECHNOLOGY, ID=36856210...\n",
                        "Saved to /home/acer/Desktop/cv/core/parsing/tests_data/resume_and_texts_kaggle/some/INFORMATION-TECHNOLOGY_36856210.json\n",
                        "Processing 4/7: Category=TEACHER, ID=12467531...\n",
                        "Saved to /home/acer/Desktop/cv/core/parsing/tests_data/resume_and_texts_kaggle/some/TEACHER_12467531.json\n",
                        "Processing 5/7: Category=ADVOCATE, ID=14445309...\n",
                        "Saved to /home/acer/Desktop/cv/core/parsing/tests_data/resume_and_texts_kaggle/some/ADVOCATE_14445309.json\n",
                        "Processing 6/7: Category=BUSINESS-DEVELOPMENT, ID=65708020...\n",
                        "Saved to /home/acer/Desktop/cv/core/parsing/tests_data/resume_and_texts_kaggle/some/BUSINESS-DEVELOPMENT_65708020.json\n",
                        "Processing 7/7: Category=HEALTHCARE, ID=23617240...\n",
                        "Saved to /home/acer/Desktop/cv/core/parsing/tests_data/resume_and_texts_kaggle/some/HEALTHCARE_23617240.json\n"
                    ]
                }
            ],
            "source": [
                "# Process and Save\n",
                "output_dir = '/home/acer/Desktop/cv/core/parsing/tests_data/resume_and_texts_kaggle/some'\n",
                "os.makedirs(output_dir, exist_ok=True)\n",
                "\n",
                "for i, sample in enumerate(samples):\n",
                "    cat = sample['Category']\n",
                "    rid = sample['ID']\n",
                "    text = sample['Resume_str']\n",
                "    \n",
                "    print(f\"Processing {i+1}/{len(samples)}: Category={cat}, ID={rid}...\")\n",
                "    try:\n",
                "        resume = convert_to_json(text)\n",
                "        \n",
                "        # Save JSON\n",
                "        output_path = os.path.join(output_dir, f\"{cat}_{rid}.json\")\n",
                "        with open(output_path, \"w\") as f:\n",
                "            f.write(resume.model_dump_json(indent=2))\n",
                "        print(f\"Saved to {output_path}\")\n",
                "        \n",
                "        # Also save original text for reference\n",
                "        text_path = os.path.join(output_dir, f\"{cat}_{rid}.txt\")\n",
                "        with open(text_path, \"w\") as f:\n",
                "            f.write(text)\n",
                "            \n",
                "    except Exception as e:\n",
                "        print(f\"Error processing {rid}: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv (3.10.12)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
